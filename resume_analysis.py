import os
import fitz  # PyMuPDF
import re
from openai import AzureOpenAI
from dotenv import load_dotenv
from typing import Tuple

# í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ë¡œë“œ
from prompts import EVALUATE_RESUME_PROMPT, GENERATE_SEARCH_QUERY_PROMPT

load_dotenv()

# GPT í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = AzureOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    azure_endpoint=os.getenv("OPENAI_ENDPOINT"),
    api_version="2024-02-15-preview"
)

def extract_text_from_pdf(pdf_path: str) -> str:
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    doc = fitz.open(pdf_path)
    return "\n".join([page.get_text() for page in doc])

def evaluate_resume(text: str) -> str:
    """GPTë¥¼ ì‚¬ìš©í•´ ì´ë ¥ì„œ í‰ê°€"""
    prompt = EVALUATE_RESUME_PROMPT.format(text=text)
    response = client.chat.completions.create(
        model=os.getenv("OPENAI_DEPLOYMENT"),
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    return response.choices[0].message.content

def extract_skills_and_category(report_text: str) -> Tuple[list, str]:
    """
    GPT ë¦¬í¬íŠ¸ì—ì„œ ê¸°ìˆ  ìŠ¤íƒê³¼ ì§ë¬´ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œ
    """
    skills_match = re.findall(r"(?:ê¸°ìˆ \s*ìŠ¤íƒ|ê¸°ìˆ \s*ëª©ë¡)[^\n]*:\s*(.*)", report_text)
    category_match = re.findall(r"(?:ì§ë¬´\s*ì¹´í…Œê³ ë¦¬|ì§ë¬´\s*ë¶„ë¥˜|ì§ë¬´\s*ìœ í˜•)[^\n]*:\s*(.*)", report_text)

    skills = [s.strip() for s in re.split(r"[,\â€¢Â·]", skills_match[0])] if skills_match else []
    category = category_match[0].strip() if category_match else None
    return skills, category

# def generate_search_query(report: str) -> str:
#     """
#     GPTì—ê²Œ ì§ë¬´ ìš”ì•½ì„ ê¸°ë°˜ìœ¼ë¡œ ê°„ê²°í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ê²Œ í•¨
#     """
#     prompt = f"""
# ë‹¤ìŒ ì´ë ¥ì„œ í‰ê°€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ FAISS ê²€ìƒ‰ì— ì í•©í•œ **ê°„ê²°í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì–´**ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.
# ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ ë¹¼ê³ , í•µì‹¬ ì§ë¬´ ì¹´í…Œê³ ë¦¬ì™€ ê¸°ìˆ  í‚¤ì›Œë“œë§Œ í¬í•¨í•´ ì£¼ì„¸ìš”. (20ë‹¨ì–´ ì´í•˜)

# ì´ë ¥ì„œ í‰ê°€ ìš”ì•½:
# {report}

# ê²€ìƒ‰ì–´:
# """
#     response = client.chat.completions.create(
#         model=os.getenv("OPENAI_DEPLOYMENT"),
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.2
#     )
#     return response.choices[0].message.content.strip()

def generate_search_query(report: str) -> str:
    prompt = GENERATE_SEARCH_QUERY_PROMPT.format(report=report)
    response = client.chat.completions.create(
        model=os.getenv("OPENAI_DEPLOYMENT"),
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    return response.choices[0].message.content.strip()[:100]  # 100ì ì´ë‚´ ì œí•œ


def generate_query_from_report(report_text: str) -> Tuple[str, list, str]:
    """
    GPT ë¦¬í¬íŠ¸ì—ì„œ ê¸°ìˆ /ì§ë¬´ ì¶”ì¶œ â†’ GPT ê²€ìƒ‰ì–´ ìƒì„±ê¹Œì§€ í•œ ë²ˆì—
    """
    skills, category = extract_skills_and_category(report_text)
    gpt_query = generate_search_query(report_text)
    return gpt_query, skills, category


# í…ŒìŠ¤íŠ¸ìš© ì˜ˆì‹œ ì‹¤í–‰
if __name__ == "__main__":
    pdf_path = "resume.pdf"
    text = extract_text_from_pdf(pdf_path)
    report = evaluate_resume(text)
    query, skills, category = generate_query_from_report(report)

    print("ğŸ“„ í‰ê°€ ìš”ì•½:\n", report)
    print("\nğŸ” ì¶”ì²œ ì¿¼ë¦¬:", query)
    print("ğŸ¯ ê¸°ìˆ  ìŠ¤íƒ:", skills)
    print("ğŸ“Œ ì¹´í…Œê³ ë¦¬:", category)
