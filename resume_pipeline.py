import os
from dotenv import load_dotenv
from openai import AzureOpenAI
from upload_to_blob import upload_pdf_to_blob
from resume_analysis import (
    extract_text_from_pdf,
    evaluate_resume,
    extract_skills_and_category,
    generate_query_from_report,
)
from recommend_jobs_from_faiss import search_faiss_job_ids, get_job_details_from_ids
from store_to_db import insert_to_database

# í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ë¡œë“œ
from prompts import COT_ANALYSIS_PROMPT_TEMPLATE

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ğŸ” .env ê¸°ì¤€ ë°˜ì˜)
client = AzureOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    api_version="2024-02-15-preview",
    azure_endpoint=os.getenv("OPENAI_ENDPOINT")
)

def generate_cot_analysis(user_skills, user_category, job_description, job_title, similarity_score, search_query):
    """
    GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì²œ ì´ìœ ë¥¼ CoT ë°©ì‹ìœ¼ë¡œ ë¶„ì„
    """
    formatted_skills = ", ".join(user_skills) if user_skills else "ì •ë³´ ì—†ìŒ"

    prompt = COT_ANALYSIS_PROMPT_TEMPLATE.format(
        user_category=user_category or "ì •ë³´ ì—†ìŒ",
        user_skills=formatted_skills,
        search_query=search_query,
        job_title=job_title,
        similarity_score=similarity_score,
        job_description=job_description[:1000]
    )

    try:
        response = client.chat.completions.create(
            model=os.getenv("OPENAI_DEPLOYMENT", "gpt-4"),
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì±„ìš©ê³µê³  ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  ë…¼ë¦¬ì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.3
        )
        return response.choices[0].message.content.strip()

    except Exception as e:
        return f"GPT ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def run_pipeline(user_id, pdf_path):
    print("\nì´ë ¥ì„œ ìë™ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘\n")

    # 1. Azure Blob ì—…ë¡œë“œ
    print("[1] Azure Blob ì—…ë¡œë“œ ì‹œì‘...")
    blob_url = upload_pdf_to_blob(pdf_path, user_id)
    print(f"  ì—…ë¡œë“œ ì™„ë£Œ. Blob URL: {blob_url}")

    # 2. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
    print("\n[2] ì´ë ¥ì„œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
    text = extract_text_from_pdf(pdf_path)
    print("  í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ")
    print("  ì¶”ì¶œ í…ìŠ¤íŠ¸ (ì• 500ì):\n", text[:500], "\n...")

    # 3. GPT ì´ë ¥ì„œ í‰ê°€
    print("\n[3] GPT ê¸°ë°˜ ì´ë ¥ì„œ í‰ê°€ ì¤‘...")
    summary = evaluate_resume(text)
    print("  í‰ê°€ ì™„ë£Œ")
    print("  í‰ê°€ ìš”ì•½:\n", summary[:700], "\n...")

    # 4. ê¸°ìˆ ìŠ¤íƒ/ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ë° ì¿¼ë¦¬ ìƒì„±
    print("\n[4] ê¸°ìˆ  ìŠ¤íƒ ë° ì§ë¬´ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ...")
    skills, category = extract_skills_and_category(summary)
    print(f"  ì¶”ì¶œëœ ê¸°ìˆ  ìŠ¤íƒ: {skills}")
    print(f"  ì¶”ì • ì§ë¬´ ì¹´í…Œê³ ë¦¬: {category}")

    # generate_query_from_reportê°€ listë¥¼ ë°˜í™˜í•  ê²½ìš° ëŒ€ë¹„
    query_raw = generate_query_from_report(summary)

    if isinstance(query_raw, list):
        query = ' '.join(str(q) for q in query_raw).strip()
    else:
        query = str(query_raw).strip()

    print(f"  ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±: '{query}'")

    # 5. FAISS ì±„ìš©ê³µê³  ì¶”ì²œ
    print("\n[5] FAISS ì±„ìš©ê³µê³  ì¶”ì²œ ì‹œì‘...")

    # FAISS ê²€ìƒ‰ API í˜¸ì¶œ â†’ similarity_score í¬í•¨ëœ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    job_id_results = search_faiss_job_ids(query)  # â†’ List[Dict] í˜•íƒœ: [{"job_id": ..., "similarity_score": ...}, ...]

    # job_idë§Œ ì¶”ì¶œ
    job_ids = [job["job_id"] for job in job_id_results]

    # RDBì—ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ
    recommendations = get_job_details_from_ids(job_ids)
    print(f"  ì¶”ì²œëœ ì±„ìš©ê³µê³  ìˆ˜: {len(recommendations)}")

    # ì¶”ì²œ ë‚´ìš© ì¶œë ¥
    print("\nì¶”ì²œ ê²°ê³¼ ìš”ì•½")
    if job_id_results and recommendations:
        for i, job in enumerate(recommendations, 1):
            matched = next((j for j in job_id_results if j["job_id"] == job["job_id"]), {})
            score = matched.get("similarity_score", 0.0)
            print(f"{i}. {job['position_title']} (ìœ ì‚¬ë„: {score:.3f})")
            print(f"   ê²Œì‹œì¼: {job.get('posted_at', 'N/A')}")
            print(f"   ì„¤ëª… ìš”ì•½: {job.get('description', '')[:200]}...")
            print("-" * 60)
    else:
        print("ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        if not job_id_results:
            print("  â†’ FAISSì—ì„œ ìœ ì‚¬í•œ ì±„ìš©ê³µê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        elif job_id_results and not recommendations:
            print("  â†’ FAISSëŠ” job_idë¥¼ ë°˜í™˜í–ˆì§€ë§Œ DBì—ì„œ í•´ë‹¹ ê³µê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


    # CoT ì¶”ì²œ ì´ìœ  ìƒì„¸ ë¶„ì„
    if recommendations:
        print("\n" + "="*80)
        print("ì¶”ì²œ ì´ìœ  ìƒì„¸ ë¶„ì„ (GPT Chain of Thought)")
        print("="*80)
        
        for i, job in enumerate(recommendations, 1):
            matched = next((j for j in job_id_results if j["job_id"] == job["job_id"]), {})
            score = matched.get("similarity_score", 0.0)
            
            print(f"\n[ì¶”ì²œ #{i}] {job['position_title']}")
            print("-" * 50)
            
            # GPT CoT ë¶„ì„ ìƒì„±
            cot_analysis = generate_cot_analysis(
                user_skills=skills,
                user_category=category,
                job_description=job.get('description', ''),
                job_title=job['position_title'],
                similarity_score=score,
                search_query=query
            )
            
            print(cot_analysis)
            
            if i < len(recommendations):  # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´ êµ¬ë¶„ì„ 
                print("\n" + "="*80)

    # 6. ê²°ê³¼ DB ì €ì¥
    print("\n[6] DBì— ê²°ê³¼ ì €ì¥ ì¤‘...")
    resume_id = insert_to_database(user_id, blob_url, summary, skills, category, recommendations)
    print(f"  ì €ì¥ ì™„ë£Œ. Resume ID: {resume_id}")

    print("\nì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
    return resume_id


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("user_id", type=int, help="ì‚¬ìš©ì ID")
    parser.add_argument("pdf_path", type=str, help="PDF ê²½ë¡œ")
    args = parser.parse_args()

    run_pipeline(args.user_id, args.pdf_path)