import os
from dotenv import load_dotenv
from openai import AzureOpenAI
from upload_to_blob import upload_pdf_to_blob
from resume_analysis import (
    extract_text_from_pdf,
    evaluate_resume,
    extract_skills_and_category,
    generate_query_from_report,
)
from recommend_jobs_from_faiss import search_faiss_job_ids, get_job_details_from_ids
from store_to_db import insert_to_database

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = AzureOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    api_version="2024-02-15-preview",
    azure_endpoint=os.getenv("OPENAI_ENDPOINT")
)

def generate_cot_analysis(user_skills, user_category, job_description, job_title, similarity_score, search_query):
    prompt = f"""ë‹¹ì‹ ì€ ì±„ìš©ê³µê³  ì¶”ì²œ ì‹œìŠ¤í…œì˜ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì™œ ì´ ì±„ìš©ê³µê³ ê°€ ì¶”ì²œë˜ì—ˆëŠ”ì§€ ë…¼ë¦¬ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

**ì‚¬ìš©ì ì •ë³´:**
- ì§ë¬´ ì¹´í…Œê³ ë¦¬: {user_category}
- ê¸°ìˆ  ìŠ¤íƒ: {', '.join(user_skills) if user_skills else 'ì •ë³´ ì—†ìŒ'}
- ê²€ìƒ‰ ì¿¼ë¦¬: {search_query}

**ì¶”ì²œëœ ì±„ìš©ê³µê³ :**
- ì§ë¬´ëª…: {job_title}
- ìœ ì‚¬ë„ ì ìˆ˜: {similarity_score:.3f}
- ì±„ìš©ê³µê³  ë‚´ìš©: {job_description[:1000]}...

**ë¶„ì„ ìš”ì²­ì‚¬í•­:**
1. ìœ ì‚¬ë„ ì ìˆ˜ê°€ {similarity_score:.3f}ì¸ ì´ìœ ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”
2. ì‚¬ìš©ìì˜ ê¸°ìˆ  ìŠ¤íƒê³¼ ì±„ìš©ê³µê³ ì˜ ìš”êµ¬ì‚¬í•­ì´ ì–´ë–»ê²Œ ë§¤ì¹­ë˜ëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”
3. ì§ë¬´ ì¹´í…Œê³ ë¦¬ì˜ ì—°ê´€ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”
4. ìµœì¢…ì ìœ¼ë¡œ ì´ ì¶”ì²œì´ ì ì ˆí•œì§€ íŒë‹¨í•˜ê³  ê·¸ ê·¼ê±°ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”

**ì¶œë ¥ í˜•ì‹:**
ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”. ë¶ˆí•„ìš”í•œ ìˆ˜ì‚¬ë‚˜ ê³¼ì¥ì€ í”¼í•˜ê³  ê°ê´€ì  ì‚¬ì‹¤ì— ê¸°ë°˜í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
    
    try:
        response = client.chat.completions.create(
            model=os.getenv("OPENAI_DEPLOYMENT", "gpt-4"),
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì±„ìš©ê³µê³  ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  ë…¼ë¦¬ì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.3
        )
        return response.choices[0].message.content.strip()

    except Exception as e:
        return f"GPT ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def run_pipeline(user_id, pdf_path):
    print("\nì´ë ¥ì„œ ìë™ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘\n")

    # 1. Azure Blob ì—…ë¡œë“œ
    print("[1] Azure Blob ì—…ë¡œë“œ ì‹œì‘...")
    blob_url = upload_pdf_to_blob(pdf_path, user_id)
    print(f"  ì—…ë¡œë“œ ì™„ë£Œ. Blob URL: {blob_url}")

    # 2. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
    print("\n[2] ì´ë ¥ì„œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
    text = extract_text_from_pdf(pdf_path)
    print("  í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ")
    print("  ì¶”ì¶œ í…ìŠ¤íŠ¸ (ì• 500ì):\n", text[:500], "\n...")

    # 3. GPT ì´ë ¥ì„œ í‰ê°€
    print("\n[3] GPT ê¸°ë°˜ ì´ë ¥ì„œ í‰ê°€ ì¤‘...")
    summary = evaluate_resume(text)
    print("  í‰ê°€ ì™„ë£Œ")
    print("  í‰ê°€ ìš”ì•½:\n", summary[:700], "\n...")

    # 4. ê¸°ìˆ ìŠ¤íƒ/ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ë° ì¿¼ë¦¬ ìƒì„±
    print("\n[4] ê¸°ìˆ  ìŠ¤íƒ ë° ì§ë¬´ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ...")
    skills, category = extract_skills_and_category(summary)
    print(f"  ì¶”ì¶œëœ ê¸°ìˆ  ìŠ¤íƒ: {skills}")
    print(f"  ì¶”ì • ì§ë¬´ ì¹´í…Œê³ ë¦¬: {category}")

    query_raw = generate_query_from_report(summary)
    query = ' '.join(query_raw) if isinstance(query_raw, list) else str(query_raw).strip()
    print(f"  ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±: '{query}'")

    # 5. FAISS ì±„ìš©ê³µê³  ì¶”ì²œ
    print("\n[5] FAISS ì±„ìš©ê³µê³  ì¶”ì²œ ì‹œì‘...")
    job_id_results = search_faiss_job_ids(query)
    job_ids = [job["job_id"] for job in job_id_results]
    recommendations = get_job_details_from_ids(job_ids)

    # ğŸ”¥ score ë³‘í•©
    for job in recommendations:
        matched = next((j for j in job_id_results if j["job_id"] == job["job_id"]), {})
        job["similarity_score"] = matched.get("similarity_score", 0.0)
    print(f"  ì¶”ì²œëœ ì±„ìš©ê³µê³  ìˆ˜: {len(recommendations)}")

    # ì¶”ì²œ ë‚´ìš© ì¶œë ¥
    print("\nì¶”ì²œ ê²°ê³¼ ìš”ì•½")
    if job_id_results and recommendations:
        for i, job in enumerate(recommendations, 1):
            matched = next((j for j in job_id_results if j["job_id"] == job["job_id"]), {})
            score = matched.get("similarity_score", 0.0)
            print(f"{i}. {job['position_title']} (ìœ ì‚¬ë„: {score:.3f})")
            print(f"   ê²Œì‹œì¼: {job.get('posted_at', 'N/A')}")
            print(f"   ì„¤ëª… ìš”ì•½: {job.get('description', '')[:200]}...")
            print("-" * 60)
    else:
        print("ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        if not job_id_results:
            print("  â†’ FAISSì—ì„œ ìœ ì‚¬í•œ ì±„ìš©ê³µê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        elif job_id_results and not recommendations:
            print("  â†’ FAISSëŠ” job_idë¥¼ ë°˜í™˜í–ˆì§€ë§Œ DBì—ì„œ í•´ë‹¹ ê³µê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # 6. CoT ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
    cot_analyses = []
    if recommendations:
        print("\n" + "="*80)
        print("ì¶”ì²œ ì´ìœ  ìƒì„¸ ë¶„ì„ (GPT Chain of Thought)")
        print("="*80)

        for i, job in enumerate(recommendations, 1):
            matched = next((j for j in job_id_results if j["job_id"] == job["job_id"]), {})
            score = matched.get("similarity_score", 0.0)

            print(f"\n[ì¶”ì²œ #{i}] {job['position_title']}")
            print("-" * 50)

            cot_analysis = generate_cot_analysis(
                user_skills=skills,
                user_category=category,
                job_description=job.get('description', ''),
                job_title=job['position_title'],
                similarity_score=score,
                search_query=query
            )
            print(cot_analysis)
            cot_analyses.append(cot_analysis)

            if i < len(recommendations):
                print("\n" + "="*80)

    # 7. DB ì €ì¥
    print("\n[6] DBì— ê²°ê³¼ ì €ì¥ ì¤‘...")
    resume_id = insert_to_database(
        user_id=user_id,
        blob_url=blob_url,
        summary=summary,
        skills=skills,
        category=category,
        job_recommendations=recommendations,
        search_query=query,
        cot_analyses=cot_analyses  # âœ… CoT ë¶„ì„ ê²°ê³¼ ì¶”ê°€
    )
    print(f"  ì €ì¥ ì™„ë£Œ. Resume ID: {resume_id}")

    print("\nì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
    return resume_id

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("user_id", type=int, help="ì‚¬ìš©ì ID")
    parser.add_argument("pdf_path", type=str, help="PDF ê²½ë¡œ")
    args = parser.parse_args()

    run_pipeline(args.user_id, args.pdf_path)
